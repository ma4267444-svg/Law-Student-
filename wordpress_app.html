<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Mohami AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@300;400;500;700;900&display=swap" rel="stylesheet">
    <script src="https://unpkg.com/react@18/umd/react.production.min.js" crossorigin></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js" crossorigin></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <script>
        pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';
        
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: { sans: ['Tajawal', 'sans-serif'] },
                    colors: {
                        law: { 50: '#f8f9fa', 800: '#343a40', 900: '#212529' },
                        tul8te: { black: '#121212', accent: '#a3a3a3' }
                    },
                    animation: { 'fade-in': 'fadeIn 0.5s ease-out' },
                    keyframes: { fadeIn: { '0%': { opacity: '0' }, '100%': { opacity: '1' } } }
                },
            },
        }
    </script>
    <style>
        /* Optimization for IFrame and Mobile */
        html, body { height: 100%; width: 100%; margin: 0; padding: 0; overflow: hidden; background-color: #121212; touch-action: manipulation; }
        #root { height: 100%; width: 100%; }
        /* Custom Scrollbar */
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: #121212; }
        ::-webkit-scrollbar-thumb { background: #444; border-radius: 3px; }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel" data-type="module">
        import { GoogleGenAI } from "https://esm.sh/@google/genai@1.33.0";
        import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

        // --- ğŸ”´ Ù‡Ø§Ù… Ø¬Ø¯Ø§Ù‹: Ø¶Ø¹ Ù…ÙØªØ§Ø­ API Ù‡Ù†Ø§ ---
        const GOOGLE_API_KEY = "AIzaSyB13O7v8wibBkeuIS29G1u4PRXIV4Dq8qM"; 

        // --- CONFIG ---
        const SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpnYW5senJyeHBpanZpcGdnaWVpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjU0ODcwNjMsImV4cCI6MjA4MTA2MzA2M30.0hmUg6FgYPI62oR2y9avE0s1eqIX2fDxmdsUB9EzlNk'; 
        const SUPABASE_URL = 'https://zganlzrrxpijvipggiei.supabase.co';
        const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

        const SUBJECTS = [
            { id: 'intl_private', name: 'Ù‚Ø§Ù†ÙˆÙ† Ø¯ÙˆÙ„ÙŠ Ø®Ø§Øµ', description: 'ØªÙ†Ø§Ø²Ø¹ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†ØŒ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©ØŒ ÙˆÙ…Ø±ÙƒØ² Ø§Ù„Ø£Ø¬Ø§Ù†Ø¨.', icon: 'ğŸŒ' },
            { id: 'sharia', name: 'Ø´Ø±ÙŠØ¹Ø© Ø¥Ø³Ù„Ø§Ù…ÙŠØ©', description: 'Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù…ÙˆØ§Ø±ÙŠØ« ÙˆØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªØ±ÙƒØ§Øª.', icon: 'âš–ï¸' },
            { id: 'commercial', name: 'Ù‚Ø§Ù†ÙˆÙ† ØªØ¬Ø§Ø±ÙŠ', description: 'Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª.', icon: 'ğŸ’¼' },
            { id: 'admin_judiciary', name: 'Ù‚Ø¶Ø§Ø¡ Ø¥Ø¯Ø§Ø±ÙŠ', description: 'Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆØ¯Ø¹ÙˆÙ‰ Ø§Ù„Ø¥Ù„ØºØ§Ø¡.', icon: 'ğŸ›ï¸' },
            { id: 'public_finance', name: 'Ù…Ø§Ù„ÙŠØ© Ø¹Ø§Ù…Ø©', description: 'Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆØ§Ù„Ø¶Ø±Ø§Ø¦Ø¨.', icon: 'ğŸ’°' },
        ];

        // --- UTILS ---
        function base64ToUint8Array(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
            return bytes;
        }

        async function decodeAudioData(data, ctx, sampleRate, numChannels) {
            const dataInt16 = new Int16Array(data.buffer);
            const frameCount = dataInt16.length / numChannels;
            const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);
            for (let channel = 0; channel < numChannels; channel++) {
                const channelData = buffer.getChannelData(channel);
                for (let i = 0; i < frameCount; i++) {
                    channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
                }
            }
            return buffer;
        }

        function createPcmBlob(data) {
            const l = data.length;
            const int16 = new Int16Array(l);
            for (let i = 0; i < l; i++) {
                const s = Math.max(-1, Math.min(1, data[i]));
                int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            let binary = '';
            const bytes = new Uint8Array(int16.buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) binary += String.fromCharCode(bytes[i]);
            return {
                data: btoa(binary),
                mimeType: 'audio/pcm;rate=16000',
            };
        }

        async function extractTextFromPDF(file) {
            const arrayBuffer = await file.arrayBuffer();
            const loadingTask = pdfjsLib.getDocument({ data: arrayBuffer });
            const pdf = await loadingTask.promise;
            let fullText = '';
            const maxPages = Math.min(pdf.numPages, 50); 
            for (let i = 1; i <= maxPages; i++) {
                const page = await pdf.getPage(i);
                const textContent = await page.getTextContent();
                const pageText = textContent.items.map(item => item.str).join(' ');
                fullText += `--- Page ${i} ---\n${pageText}\n`;
            }
            return fullText;
        }

        async function extractTextFromImage(file, apiKey) {
            if (!apiKey) throw new Error("API Key is required");
            const ai = new GoogleGenAI({ apiKey });
            const base64Data = await new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result.split(',')[1]);
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
            const response = await ai.models.generateContent({
                model: 'gemini-2.5-flash',
                contents: {
                    parts: [
                        { inlineData: { mimeType: file.type, data: base64Data } },
                        { text: "OCR: Extract all Arabic text." }
                    ]
                }
            });
            return response.text || "No text found.";
        }

        // --- COMPONENTS ---
        const Visualizer = ({ state, volume }) => {
            const canvasRef = React.useRef(null);
            React.useEffect(() => {
                const canvas = canvasRef.current;
                if (!canvas) return;
                const ctx = canvas.getContext('2d');
                let animationId;
                let time = 0;
                const render = () => {
                    time += 0.05;
                    const { width, height } = canvas;
                    const centerX = width / 2;
                    const centerY = height / 2;
                    ctx.clearRect(0, 0, width, height);
                    
                    let baseRadius = 60;
                    let color = '#3b5468';
                    if (state === 'CONNECTED') {
                        color = '#c5a059';
                        baseRadius = 60 + (volume * 50);
                    } else if (state === 'CONNECTING') {
                        color = '#94a3b8';
                        baseRadius = 60 + Math.sin(time * 5) * 5;
                    }

                    const gradient = ctx.createRadialGradient(centerX, centerY, baseRadius * 0.5, centerX, centerY, baseRadius * 1.5);
                    gradient.addColorStop(0, color);
                    gradient.addColorStop(1, 'rgba(255, 255, 255, 0)');
                    
                    ctx.beginPath();
                    ctx.arc(centerX, centerY, baseRadius * 1.5, 0, Math.PI * 2);
                    ctx.fillStyle = gradient;
                    ctx.fill();

                    ctx.beginPath();
                    ctx.arc(centerX, centerY, baseRadius, 0, Math.PI * 2);
                    ctx.fillStyle = color;
                    ctx.fill();
                    
                    animationId = requestAnimationFrame(render);
                };
                render();
                return () => cancelAnimationFrame(animationId);
            }, [state, volume]);
            return (
                <div className="relative flex justify-center items-center h-48 w-full">
                    <canvas ref={canvasRef} width={400} height={300} className="max-w-full h-full"/>
                </div>
            );
        };

        const App = () => {
            const [view, setView] = React.useState('DASHBOARD');
            const [selectedSubject, setSelectedSubject] = React.useState(null);
            const [sources, setSources] = React.useState([]);
            const [isProcessingFile, setIsProcessingFile] = React.useState(false);
            const [processingStatus, setProcessingStatus] = React.useState('');
            const [apiKey, setApiKey] = React.useState(GOOGLE_API_KEY || localStorage.getItem('MOHAMI_API_KEY') || '');
            const [connectionState, setConnectionState] = React.useState('DISCONNECTED');
            const [volume, setVolume] = React.useState(0);
            const [errorMsg, setErrorMsg] = React.useState(null);
            
            // Chat & History State
            const [messages, setMessages] = React.useState([]);
            const [isLoadingHistory, setIsLoadingHistory] = React.useState(false);
            const [currentInput, setCurrentInput] = React.useState('');
            const [currentOutput, setCurrentOutput] = React.useState('');

            const inputAudioContextRef = React.useRef(null);
            const outputAudioContextRef = React.useRef(null);
            const mediaStreamRef = React.useRef(null);
            const processorRef = React.useRef(null);
            const sourceNodeRef = React.useRef(null);
            const sessionRef = React.useRef(null);
            const nextStartTimeRef = React.useRef(0);
            const sourcesRef = React.useRef(new Set());
            const scrollRef = React.useRef(null);
            const fileInputRef = React.useRef(null);
            const pdfInputRef = React.useRef(null);
            const imageKbInputRef = React.useRef(null);

            React.useEffect(() => {
                if(apiKey && !GOOGLE_API_KEY) localStorage.setItem('MOHAMI_API_KEY', apiKey);
            }, [apiKey]);

            // --- Database Functions ---
            const fetchSources = async (subjectId) => {
                setProcessingStatus('Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØµØ§Ø¯Ø±...');
                const { data, error } = await supabase.from('resources').select('*').eq('subject_id', subjectId).order('created_at', { ascending: false });
                if (!error) {
                    setSources(data.map(item => ({
                        id: item.id,
                        subjectId: item.subject_id,
                        title: item.title,
                        content: item.content,
                        type: item.type,
                        createdAt: new Date(item.created_at).getTime()
                    })));
                }
                setProcessingStatus('');
            };

            const fetchHistory = async (subjectId) => {
                setIsLoadingHistory(true);
                const { data, error } = await supabase
                    .from('chat_history')
                    .select('*')
                    .eq('subject_id', subjectId)
                    .order('created_at', { ascending: true });
                
                if (!error && data) {
                    setMessages(data.map(item => ({
                        id: item.id,
                        role: item.role,
                        text: item.text,
                        timestamp: item.created_at
                    })));
                }
                setIsLoadingHistory(false);
            };

            const saveMessageToDB = async (role, text) => {
                if (!selectedSubject) return;
                // Save locally first for UI speed
                const tempId = Date.now().toString();
                // We actually set state in the stream loop, this is just for DB persistence
                
                // Save to Supabase
                const { error } = await supabase.from('chat_history').insert([{
                    subject_id: selectedSubject.id,
                    role: role,
                    text: text,
                    created_at: new Date().toISOString()
                }]);
                
                if (error) console.error("Failed to save history:", error);
            };

            const saveSourceToDB = async (source) => {
                const { data, error } = await supabase.from('resources').insert([{
                    subject_id: source.subjectId,
                    title: source.title,
                    content: source.content,
                    type: source.type,
                    created_at: new Date().toISOString()
                }]).select();
                if (data && data[0]) {
                    setSources(prev => [{
                         id: data[0].id,
                        subjectId: data[0].subject_id,
                        title: data[0].title,
                        content: data[0].content,
                        type: data[0].type,
                        createdAt: new Date(data[0].created_at).getTime()
                    }, ...prev]);
                } else if (error) {
                    alert("Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: " + error.message);
                }
            };

            const deleteSourceFromDB = async (id) => {
                await supabase.from('resources').delete().eq('id', id);
                setSources(prev => prev.filter(s => s.id !== id));
            };

            // --- Handlers ---
            const handleSubjectSelect = (subject) => {
                setSelectedSubject(subject);
                fetchSources(subject.id);
                fetchHistory(subject.id);
                setView('DETAILS');
            };

            const handleAddTextNote = async () => {
                const text = prompt("Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ:");
                if (text && selectedSubject) {
                    await saveSourceToDB({ subjectId: selectedSubject.id, title: 'Ù…Ù„Ø§Ø­Ø¸Ø©', content: text, type: 'text' });
                }
            };

            const handlePDFUpload = async (e) => {
                const file = e.target.files?.[0];
                if (!file || !selectedSubject) return;
                setIsProcessingFile(true);
                try {
                    const text = await extractTextFromPDF(file);
                    await saveSourceToDB({ subjectId: selectedSubject.id, title: file.name, content: text, type: 'pdf' });
                } catch(e) { alert("PDF Error"); }
                setIsProcessingFile(false);
            };

            const handleImageKbUpload = async (e) => {
                const file = e.target.files?.[0];
                if (!file || !selectedSubject) return;
                setIsProcessingFile(true);
                try {
                    const text = await extractTextFromImage(file, apiKey);
                    await saveSourceToDB({ subjectId: selectedSubject.id, title: `[IMG] ${file.name}`, content: text, type: 'image' });
                } catch(e) { alert("OCR Error: " + e.message); }
                setIsProcessingFile(false);
            };

            // --- Audio Logic ---
            const initAudioContexts = async () => {
                if (!inputAudioContextRef.current) inputAudioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                if (!outputAudioContextRef.current) outputAudioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });

                // CRITICAL FOR MOBILE: Resume AudioContexts on user gesture
                if (inputAudioContextRef.current.state === 'suspended') await inputAudioContextRef.current.resume();
                if (outputAudioContextRef.current.state === 'suspended') await outputAudioContextRef.current.resume();
            };

            const disconnect = React.useCallback(async () => {
                if (mediaStreamRef.current) mediaStreamRef.current.getTracks().forEach(t => t.stop());
                if (processorRef.current) processorRef.current.disconnect();
                if (sourceNodeRef.current) sourceNodeRef.current.disconnect();
                if (sessionRef.current) {
                    const session = await sessionRef.current;
                    try { session.close(); } catch(e){}
                    sessionRef.current = null;
                }
                setConnectionState('DISCONNECTED');
            }, []);

            const connect = async () => {
                const keyToUse = apiKey || GOOGLE_API_KEY;
                if (!keyToUse) { setErrorMsg("API Key Missing"); return; }
                
                try {
                    // Initialize and Resume Audio FIRST
                    await initAudioContexts();
                } catch (err) {
                    console.error("Audio Context Init Error:", err);
                }

                setConnectionState('CONNECTING');
                setErrorMsg(null);

                try {
                    let stream;
                    try {
                        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    } catch (micError) {
                         // ... (Error handling remains same)
                         setErrorMsg("âŒ ØªØ¹Ø°Ø± Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†. ØªØ£ÙƒØ¯ Ù…Ù† Ø¥ØºÙ„Ø§Ù‚ Ø£ÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø¹Ø§Ø¦Ù…Ø©.");
                         setConnectionState('DISCONNECTED');
                         return;
                    }

                    mediaStreamRef.current = stream;
                    const ai = new GoogleGenAI({ apiKey: keyToUse });
                    // Build context from sources and RECENT history (last 5 messages)
                    const recentHistory = messages.slice(-5).map(m => `${m.role === 'user' ? 'Ø§Ù„Ø·Ø§Ù„Ø¨' : 'Mohami'}: ${m.text}`).join('\n');
                    const subjectDocs = sources.map(s => `[${s.title}]: ${s.content}`).join('\n');
                    
                    const sessionPromise = ai.live.connect({
                        model: 'gemini-2.5-flash-native-audio-preview-09-2025',
                        callbacks: {
                            onopen: () => {
                                setConnectionState('CONNECTED');
                                const ctx = inputAudioContextRef.current;
                                const source = ctx.createMediaStreamSource(stream);
                                sourceNodeRef.current = source;
                                const processor = ctx.createScriptProcessor(4096, 1, 1);
                                processorRef.current = processor;
                                processor.onaudioprocess = (e) => {
                                    const inputData = e.inputBuffer.getChannelData(0);
                                    let sum = 0;
                                    for(let i=0; i < inputData.length; i++) sum += inputData[i] * inputData[i];
                                    setVolume(Math.min(Math.sqrt(sum / inputData.length) * 5, 1));
                                    const pcmBlob = createPcmBlob(inputData);
                                    sessionPromise.then(s => s.sendRealtimeInput({ media: pcmBlob }));
                                };
                                source.connect(processor);
                                processor.connect(ctx.destination);
                            },
                            onmessage: async (msg) => {
                                const serverContent = msg.serverContent;
                                if (serverContent?.modelTurn?.parts?.[0]?.text) setCurrentOutput(p => p + serverContent.modelTurn.parts[0].text);
                                if (msg.serverContent?.outputTranscription?.text) setCurrentOutput(p => p + msg.serverContent.outputTranscription.text);
                                if (msg.serverContent?.inputTranscription?.text) setCurrentInput(p => p + msg.serverContent.inputTranscription.text);
                                
                                if (serverContent?.turnComplete) {
                                    // Save to DB and State when turn is done
                                    if(currentInput.trim()) {
                                        const text = currentInput;
                                        setMessages(p => [...p, { role: 'user', text: text, id: Date.now() }]);
                                        saveMessageToDB('user', text);
                                    }
                                    if(currentOutput.trim()) {
                                        const text = currentOutput;
                                        setMessages(p => [...p, { role: 'model', text: text, id: Date.now() }]);
                                        saveMessageToDB('model', text);
                                    }
                                    setCurrentInput(''); setCurrentOutput('');
                                }

                                const base64Audio = serverContent?.modelTurn?.parts?.[0]?.inlineData?.data;
                                if (base64Audio) {
                                    const ctx = outputAudioContextRef.current;
                                    // Ensure playback timing is correct
                                    nextStartTimeRef.current = Math.max(nextStartTimeRef.current, ctx.currentTime);
                                    const audioBuffer = await decodeAudioData(base64ToUint8Array(base64Audio), ctx, 24000, 1);
                                    const source = ctx.createBufferSource();
                                    source.buffer = audioBuffer;
                                    source.connect(ctx.destination);
                                    source.start(nextStartTimeRef.current);
                                    nextStartTimeRef.current += audioBuffer.duration;
                                }
                            }
                        },
                        config: {
                            responseModalities: ['AUDIO'],
                            inputAudioTranscription: {}, outputAudioTranscription: {},
                            // Ensure Voice is Fenrir (Deep/Calm)
                            speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Fenrir' } } },
                            systemInstruction: `Ø£Ù†Øª "Mohami"ØŒ Ù…Ø¹Ù„Ù… Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©. 
                            Ø§Ù„Ù…Ø§Ø¯Ø©: ${selectedSubject?.name}.
                            
                            Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
                            ${recentHistory}

                            Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙÙŠ Ø§Ù„Ø´Ø±Ø­: 
                            ${subjectDocs}
                            `
                        }
                    });
                    sessionRef.current = sessionPromise;
                } catch(e) {
                    console.error(e);
                    setConnectionState('DISCONNECTED');
                    setErrorMsg("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: " + e.message);
                }
            };

            React.useEffect(() => {
                if(scrollRef.current) scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
            }, [messages, currentInput, currentOutput]);

            // --- RENDER ---
            if (view === 'DASHBOARD') {
                return (
                    <div className="h-full w-full overflow-y-auto p-6 flex flex-col items-center">
                        <h1 className="text-2xl font-bold text-white mb-8 mt-4">MOHAMI AI</h1>
                        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 w-full max-w-4xl">
                            {SUBJECTS.map(sub => (
                                <button key={sub.id} onClick={() => handleSubjectSelect(sub)} className="bg-law-900 border border-law-800 p-6 rounded-2xl text-right hover:border-tul8te-accent transition-all">
                                    <div className="text-4xl mb-4">{sub.icon}</div>
                                    <h2 className="text-xl font-bold text-white">{sub.name}</h2>
                                    <p className="text-sm text-gray-400">{sub.description}</p>
                                </button>
                            ))}
                        </div>
                        {!GOOGLE_API_KEY && (
                            <div className="mt-12 w-full max-w-md pb-8">
                                <input type="password" value={apiKey} onChange={e => setApiKey(e.target.value)} placeholder="API Key" className="w-full bg-law-900 border border-law-800 rounded-lg p-3 text-center"/>
                            </div>
                        )}
                    </div>
                );
            }

            if (view === 'DETAILS') {
                 return (
                    <div className="h-full w-full overflow-y-auto p-6 flex flex-col items-center">
                        <div className="w-full max-w-4xl flex justify-between mb-8">
                            <button onClick={() => setView('DASHBOARD')} className="text-gray-500">Ø¹ÙˆØ¯Ø©</button>
                            <h1 className="text-2xl font-bold">{selectedSubject.name}</h1>
                        </div>
                        <div className="w-full max-w-4xl space-y-4 pb-8">
                            <div className="bg-law-900 p-6 rounded-2xl border border-law-800 flex justify-between">
                                <div>
                                    <p className="text-tul8te-accent text-xs">Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø±</p>
                                    <p className="text-3xl font-bold">{sources.length}</p>
                                </div>
                                <div>
                                    <p className="text-tul8te-accent text-xs">Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª</p>
                                    <p className="text-3xl font-bold">{isLoadingHistory ? '...' : messages.length}</p>
                                </div>
                            </div>
                            <div className="space-y-2">
                                {sources.map(s => (
                                    <div key={s.id} className="bg-law-800 p-4 rounded-xl flex justify-between items-center">
                                        <span>{s.type === 'pdf' ? 'ğŸ“„' : 'ğŸ“'} {s.title}</span>
                                        <button onClick={() => deleteSourceFromDB(s.id)} className="text-red-500">Ø­Ø°Ù</button>
                                    </div>
                                ))}
                            </div>
                            <div className="grid grid-cols-3 gap-4">
                                <button onClick={() => pdfInputRef.current.click()} disabled={isProcessingFile} className="bg-law-900 p-4 rounded-xl border border-law-800 hover:border-tul8te-accent">ğŸ“„ PDF</button>
                                <button onClick={() => imageKbInputRef.current.click()} disabled={isProcessingFile} className="bg-law-900 p-4 rounded-xl border border-law-800 hover:border-tul8te-accent">ğŸ–¼ï¸ ØµÙˆØ±Ø©</button>
                                <button onClick={handleAddTextNote} className="bg-law-900 p-4 rounded-xl border border-law-800 hover:border-tul8te-accent">ğŸ“ Ù†Øµ</button>
                            </div>
                            <input type="file" ref={pdfInputRef} hidden accept="application/pdf" onChange={handlePDFUpload}/>
                            <input type="file" ref={imageKbInputRef} hidden accept="image/*" onChange={handleImageKbUpload}/>
                            <button onClick={() => setView('CHAT')} className="w-full py-4 bg-white text-black font-bold rounded-xl mt-8">Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø©</button>
                        </div>
                    </div>
                 );
            }

            return (
                <div className="h-full flex flex-col">
                    <header className="bg-law-900 p-4 flex justify-between items-center border-b border-law-800 flex-shrink-0">
                        <button onClick={() => { disconnect(); setView('DETAILS'); }}>Ø®Ø±ÙˆØ¬</button>
                        <h1>{selectedSubject.name}</h1>
                        <div className={`w-3 h-3 rounded-full ${connectionState === 'CONNECTED' ? 'bg-green-500' : 'bg-red-500'}`}></div>
                    </header>
                    <main className="flex-1 overflow-y-auto p-4 space-y-4" ref={scrollRef}>
                        {messages.length === 0 && !currentInput && (
                            <div className="text-center text-gray-500 mt-10">Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø³Ø§Ø¨Ù‚Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø©. Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¢Ù†!</div>
                        )}
                        {messages.map((m, idx) => (
                            <div key={m.id || idx} className={`flex ${m.role === 'user' ? 'justify-start' : 'justify-end'}`}>
                                <div className={`max-w-[85%] p-4 rounded-2xl ${m.role === 'user' ? 'bg-law-800' : 'bg-gray-900 border border-law-800'}`}>
                                    {m.text}
                                </div>
                            </div>
                        ))}
                        {currentInput && <div className="text-gray-500 text-sm animate-pulse">Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹: {currentInput}</div>}
                        {currentOutput && <div className="text-tul8te-accent text-sm">Mohami: {currentOutput}</div>}
                    </main>
                    <div className="bg-law-900 p-4 border-t border-law-800 flex flex-col items-center flex-shrink-0">
                        <Visualizer state={connectionState} volume={volume} />
                        <button onClick={connectionState === 'CONNECTED' ? disconnect : connect} className={`mt-4 w-16 h-16 rounded-full flex items-center justify-center border-2 ${connectionState === 'CONNECTED' ? 'border-red-500 bg-red-900/50 animate-pulse' : 'border-white bg-black'}`}>
                            {connectionState === 'CONNECTING' ? '...' : connectionState === 'CONNECTED' ? 'â– ' : 'ğŸ¤'}
                        </button>
                        {errorMsg && <p className="text-red-500 mt-2 text-xs text-center">{errorMsg}</p>}
                    </div>
                </div>
            );
        };

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>